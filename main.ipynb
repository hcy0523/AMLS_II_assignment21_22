{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7438a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.6.0\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCY\\AppData\\Roaming\\Python\\Python38\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCY\\AppData\\Roaming\\Python\\Python38\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "import A.SubtaskA as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7eff8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassA=A.A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7687258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('neutral', 1): 10342, ('positive', 2): 7059, ('negative', 0): 3231}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     10\u001b[0m epochOfModel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m \u001b[38;5;66;03m# save model in 27th epoch.\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m X_train, X_test, Y_train, Y_test,vocab,embed_dict \u001b[38;5;241m=\u001b[39m \u001b[43mClassA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFinal_PreProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43mWord_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model_A \u001b[38;5;241m=\u001b[39m ClassA\u001b[38;5;241m.\u001b[39mmodel_build(vocab,embed_dict)\n\u001b[0;32m     14\u001b[0m train_acc, val_acc,history \u001b[38;5;241m=\u001b[39m ClassA\u001b[38;5;241m.\u001b[39mmodel_train(X_train, Y_train,model_A,validation_split,batch_size,Train_epoch,epochOfModel)\n",
      "File \u001b[1;32mD:\\UCL-ELEC0135\\Assignments\\A\\SubtaskA.py:179\u001b[0m, in \u001b[0;36mA.Final_PreProcess\u001b[1;34m(self, address, window, min_count, epochs, seq_len)\u001b[0m\n\u001b[0;32m    177\u001b[0m distrib\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_distrib(dataA)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(distrib)\n\u001b[1;32m--> 179\u001b[0m token,vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mText\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m embed_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2vec(token,window,min_count,epochs)\n\u001b[0;32m    182\u001b[0m X_train, X_test, Y_train, Y_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit(dataA\u001b[38;5;241m.\u001b[39mText,vocab,dataA\u001b[38;5;241m.\u001b[39mlabel,seq_len,embed_dict)\n",
      "File \u001b[1;32mD:\\UCL-ELEC0135\\Assignments\\A\\SubtaskA.py:110\u001b[0m, in \u001b[0;36mA.Tokenize\u001b[1;34m(self, Texts)\u001b[0m\n\u001b[0;32m    108\u001b[0m token\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Text \u001b[38;5;129;01min\u001b[39;00m Texts:\n\u001b[1;32m--> 110\u001b[0m     words \u001b[38;5;241m=\u001b[39m [sentence \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_process_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mText\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m (sentence\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sentence\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m    111\u001b[0m     token\u001b[38;5;241m.\u001b[39mappend(words)\n\u001b[0;32m    112\u001b[0m words\u001b[38;5;241m=\u001b[39m[word \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m token \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\ekphrasis\\classes\\preprocessor.py:318\u001b[0m, in \u001b[0;36mTextPreProcessor.pre_process_doc\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# unpack contractions: i'm -> i am, can't -> can not...\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# remove textacy dependency\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack_contractions:\n\u001b[1;32m--> 318\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43munpack_contractions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# omit allcaps if inside hashtags\u001b[39;00m\n\u001b[0;32m    321\u001b[0m doc \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m +\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, doc)  \u001b[38;5;66;03m# remove repeating spaces\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\ekphrasis\\utils\\nlp.py:59\u001b[0m, in \u001b[0;36munpack_contractions\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     57\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb)([Ii])\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2 am\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m     58\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb)([Ll]et)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2 us\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[1;32m---> 59\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb)([Ww])on\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2ill not\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb)([Ss])han\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2hall not\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m     61\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb)([Yy])(?:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall|a\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mll)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2ou all\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "File \u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msub(repl, string, count)\n",
      "File \u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\re.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    292\u001b[0m     flags \u001b[38;5;241m=\u001b[39m flags\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cache[\u001b[38;5;28mtype\u001b[39m(pattern), pattern, flags]\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "address='Datasets/A/twitter-2016train-A.txt'\n",
    "window=5 \n",
    "min_count=1 \n",
    "Word_epochs=100 \n",
    "seq_len=100 \n",
    "Train_epoch=50 \n",
    "batch_size=128\n",
    "validation_split=0.2\n",
    "epochOfModel=27 # save model in 27th epoch.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test,vocab,embed_dict = ClassA.Final_PreProcess(address,window,min_count,Word_epochs,seq_len)\n",
    "model_A = ClassA.model_build(vocab,embed_dict)\n",
    "train_acc, val_acc,history = ClassA.model_train(X_train, Y_train,model_A,validation_split,batch_size,Train_epoch,epochOfModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f1b5c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_acc, val_acc,history \u001b[38;5;241m=\u001b[39m ClassA\u001b[38;5;241m.\u001b[39mmodel_train(\u001b[43mX_train\u001b[49m, Y_train,model_A,validation_split,batch_size,Train_epoch,epochOfModel)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_acc, val_acc,history = ClassA.model_train(X_train, Y_train,model_A,validation_split,batch_size,Train_epoch,epochOfModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9535eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train, X_test, Y_train, Y_test,vocab,embed_dict,model_A,train_acc, val_acc,history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
